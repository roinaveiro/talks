{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Simulation-based Bayesian Optimization\"\n",
        "author: \"Roi Naveiro\"\n",
        "institute: \"CUNEF University\"\n",
        "format:\n",
        "  revealjs: \n",
        "    slide-number: true\n",
        "    chalkboard: \n",
        "      buttons: false\n",
        "    preview-links: auto\n",
        "    css: styles.css\n",
        "    #footer: <https://roinaveiro.github.io>\n",
        "resources:\n",
        "  - demo.pdf\n",
        "---"
      ],
      "id": "6a0486cb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Molecular Desing\n"
      ],
      "id": "d511b546"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "slide"
      },
      "source": [
        "#| code-line-numbers: '|6|9'\n",
        "#| echo: true\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "r = np.arange(0, 2, 0.01)\n",
        "theta = 2 * np.pi * r\n",
        "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
        "ax.plot(theta, r)\n",
        "ax.set_rticks([0.5, 1, 1.5, 2])\n",
        "ax.grid(True)\n",
        "plt.show()"
      ],
      "id": "e7cf5a8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The problem\n",
        "\n",
        "## Representing molecules\n",
        "\n",
        "## Predicting properties\n",
        "\n",
        "## The problem\n",
        "\n",
        "Find extreme of objective function \n",
        "\n",
        "\\begin{equation*}\n",
        "\\arg\\max_{x \\in \\mathcal{S}} f(x)\n",
        "\\end{equation*}\n",
        "\n",
        "* No closed form for $f(x)$\n",
        "\n",
        "* $f(x)$ is expensive to evaluate\n",
        "\n",
        "* Possibly discrete structured domain $\\mathcal{S}$ (e.g. $\\mathcal{S} = [k]^p$)\n",
        "\n",
        "* We can query at $x$  and obtain a (possibly noisy) evaluation of $f(x)$\n",
        "\n",
        "## Goal\n",
        "\n",
        "Get good estimates of global maximum, with **few objective function evaluations**\n",
        "\n",
        "## Bayesian Optimization (in a nutshell)\n",
        "\n",
        "Imagine we have access to: $\\mathcal{D}_{1:T} = \\lbrace x_t, y_t \\rbrace_{t=1}^T$\n",
        "where $y_t  \\equiv y(x_t) \\equiv f(x_t) + \\epsilon$, $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$\n",
        "<br>\n",
        "<br>\n",
        "Q: Where to evaluate next? \n",
        "\n",
        "A: Location with max Expected Utility^[Following Bayesian Decision Theory principles]\n",
        "\n",
        "## Bayesian Optimization (in a nutshell)\n",
        "\n",
        "To do this:\n",
        "\n",
        "1. Create **probabilistic model** of response given covariates\n",
        "\n",
        "2. Given prior knowledge about $f(x)$ and evidence coming from $\\mathcal{D}_{1:T}$, summarise our **beliefs about next sample result** through PPD\n",
        "\n",
        "\\begin{equation*}\n",
        "p[y_{T+1} | x_{T+1}, \\mathcal{D}_{1:T}] \n",
        "\\end{equation*}\n",
        "\n",
        "## Bayesian Optimization (in a nutshell)\n",
        "\n",
        "3. Find\n",
        "\n",
        "\\begin{equation*}\n",
        "x^*_{T+1} = \\arg\\max_{x_{T+1} \\in \\mathcal{S}}  \\mathbb{E}_{y_{T+1} | x_{T+1}, \\mathcal{D}_{1:T}} [u(y_{T+1}, x_{T+1} )]\n",
        "\\end{equation*}\n",
        "\n",
        "## Exploration - Exploitation\n",
        "\n",
        "Utility function\n",
        "\n",
        "## Bayesian Optimization - Difficulties\n",
        "\n",
        "$\\mathcal{S}$ could be a combinatorial search space (or even more complex!). We need:\n",
        "\n",
        "1. Suitable models of response given covariates\n",
        "\n",
        "2. Solve a combinatorial optimization in Step 3.\n",
        "\n",
        "## SBBO\n",
        "\n",
        "We propose **Simulation Based Bayesian Optimization (SBBO)**: an approach to 2 that just requires **sampling from PPD** allowing us to use a wide variaty of models in 1\n",
        "\n",
        "\n",
        "## SBBO \n",
        "\n",
        "The EU is:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "\\Psi(x) \\equiv \\int u(y, x ) \\cdot \\pi(y \\vert x, \\mathcal{D}_{1:T} ) d y\n",
        "\\end{eqnarray*}\n",
        "\n",
        "Given **non-negative** and **bounded** utility, recast EU maximization as a simulation from \n",
        "\n",
        "\\begin{eqnarray*}\n",
        "g(x, y) \\propto u(y, x ) \\cdot \\pi(y \\vert x, \\mathcal{D}_{1:T} ) \n",
        "\\end{eqnarray*}\n",
        "\n",
        "**NOTE:** mode of marginal in $x$ is $x^*_{T+1}$!\n",
        "\n",
        "## SBBO \n",
        "\n",
        "* We could simulate from $g(y, x)$ and find the mode... just limited for low dimensional $x$\n",
        "\n",
        "## SBBO \n",
        "\n",
        "* Alternative: **auxiliary distribution**\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "g_H(x, y_1, \\dots, y_H) \\propto \\prod_{h=1}^H u(y^h, x ) \\cdot \\pi(y^h \\vert x, \\mathcal{D}_{1:T} ) \n",
        "\\end{eqnarray*}\n",
        "\n",
        "for positive integer $H$. Marginal in $x$ \n",
        "\n",
        "\\begin{eqnarray*}\n",
        "g_H(x) \\propto \\Psi(x)^H\n",
        "\\end{eqnarray*}\n",
        "\n",
        "## SBBO \n",
        "\n",
        "Muller et. al. (2004): inhomogeneus MCMC simulation from $g_H(y, x)$ with increasing $H=H_n$ such that **stationary distribution** for fixed $H$ is $g_H$ converges to uniform over set of expected utility maxmizers\n",
        "\n",
        "## SBBO - Gibbs\n",
        "\n",
        "Let's define\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "g_H(x, y_1, \\dots, y_H) \\propto \\exp \\left \\lbrace\n",
        "\\sum_{h=1}^H \\log[ u(y^h, x ) ] + \\log [\\pi(y^h \\vert x, \\mathcal{D}_{1:T}) ] \\right \\rbrace \n",
        "\\end{eqnarray*}\n",
        "\n",
        "## SBBO - Gibbs\n",
        "\n",
        "Recall $x \\in [k]^p$ is a $p$-dimensional vector of $k$-levels categorical variables. Then:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "g_H(x_q \\vert \\cdot) \\propto \\exp \\left \\lbrace\n",
        "\\sum_{h=1}^H \\log[ u(y^h, x_q \\cup x_{-q}  ) ] + \\log [\\pi(y^h \\vert x_q \\cup x_{-q}, \\mathcal{D}_{1:T}) ] \\right \\rbrace \n",
        "\\end{eqnarray*}\n",
        "\n",
        "*Softmax* over  $\\sum_{h=1}^H \\log[ u(y^h, x_q \\cup x_{-q}  ) ] + \\log [\\pi(y^h \\vert x_q \\cup x_{-q}, \\mathcal{D}_{1:T}) ]$ \n",
        "for every level $x_q$!\n",
        "\n",
        "## SBBO - Gibbs\n",
        "\n",
        "Assume current state of chain is $x, y_1, \\dots, y_H$. Iterate\n",
        "\n",
        "1. For $q=1, \\dots, p$, sample $x_q \\sim g_H(x_q \\vert \\cdot)$ \n",
        "<br>\n",
        "<br>\n",
        "2. For $h=1, \\dots, H$, sample $y_h \\sim g_H(y_h \\vert \\cdot)$, using a Metropolis-Hastings step. \n",
        "<br>\n",
        "<br>\n",
        "3. Increase  $H$ according to chosen cooling schedule.\n",
        "\n",
        "## SBBO - Gibbs\n",
        "\n",
        "We need to evaluate $\\sum_{h=1}^H \\log[ u(y^h, x_q \\cup x_{-q}  ) ] + \\log [\\pi(y^h \\vert x_q \\cup x_{-q}, \\mathcal{D}_{1:T}) ]$ ... \n",
        "<br>\n",
        "<br>\n",
        "we need closed form **log posterior predictive distribution**\n",
        "\n",
        "## SBBO - Metropolis\n",
        "\n",
        "* Update $y^h$ and $x_q$ at the same time\n",
        "\n",
        "* Use a symmetric proposal for $x_q$\n",
        "\n",
        "* Use $\\pi(y^h \\vert x, \\mathcal{D}_{1:T})$ as proposal for $y_h$\n",
        "\n",
        "## SBBO - Metropolis\n",
        "\n",
        "Assume current state of chain is $x, y_1, \\dots, y_H$.\n",
        "\n",
        "Define $v = \\frac{1}{H} \\sum_h \\log u(x, y_h)$. Iterate:\n",
        "\n",
        "1. For $q=1, \\dots, p$:\n",
        "\n",
        "    * Sample $\\tilde{x}_q$ from symmetric proposal\n",
        "\n",
        "    * Sample $\\tilde{y}_h \\sim \\pi(y^h \\vert \\tilde{x}_q \\cup x_{-q}, \\mathcal{D}_{1:T} )$ for $h=1, \\dots, H$\n",
        "\n",
        "    * Evaluate $\\tilde{v} = \\frac{1}{H} \\sum_h \\log u(\\tilde{x}_q \\cup x_{-q}, \\tilde{y}_h)$\n",
        "\n",
        "    * With probability $\\min \\left[1, \\exp (H \\tilde{v} - H v)\\right]$ set $v = \\tilde{v}$ and $x = \\tilde{x}_q \\cup x_{-q}$\n",
        "\n",
        "2. Increase $H$ according to chosen cooling schedule\n",
        "\n",
        "## SBBO - Implementation details\n",
        "\n",
        "* We run the previous algorithm increasing $H$ until certain value.\n",
        "\n",
        "* Last generated $x$ is the new evaluation\n",
        "\n",
        "* We propose several probabilistic models of response given covariates for which we have sampling access to their PPD\n",
        "\n",
        "## SBBO - Tanimoto GP\n",
        "\n",
        "* Uncertainty on $f(x)$ modelled through Gaussian Process\n",
        "\n",
        "* $x \\in \\lbrace 0, 1 \\rbrace^p$. Kernel function:\n",
        "\n",
        "\\begin{equation*}\n",
        "k(x, x') = \\frac{x \\cdot x'}{\\Vert x \\Vert^2 + \\Vert x' \\Vert^2 - x \\cdot x'}\n",
        "\\end{equation*}\n",
        "\n",
        "* **PPD is Gaussian with certain mean and variance analytically available**\n",
        "\n",
        "## SBBO - Sparse Bayesian linear regression\n",
        "\n",
        "As in Baptista and Poloczek (2018):\n",
        "\\begin{eqnarray*}\n",
        "&& y = \\alpha_0 + \\sum_j \\alpha_j x_j + \\sum_{i,j>i} \\alpha_{ij} x_i x_j + \\epsilon\\\\\n",
        "%\n",
        "&& \\alpha_k \\vert \\beta_k, \\tau, \\sigma^2 \\sim \\mathcal{N}(0, \\beta_k^2 \\tau^2 \\sigma^2)\\\\\n",
        "%\n",
        "&& \\beta_k, \\tau \\sim \\mathcal{C}^+(0, 1)\\\\\n",
        "%\n",
        "&& P(\\sigma^2) \\propto \\sigma^{-2}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "* **PPD accesible through MCMC (Gibbs sampler)**\n",
        "\n",
        "\n",
        "## SBBO - NGBoost\n",
        "\n",
        "* Output given covariates modelled through\n",
        "$y \\vert x \\sim P_\\theta (x)$\n",
        "\n",
        "* Where $\\theta(x)$ are obtained through an additive combination of $M$ base learners and an initial $\\theta^{(0)}$\n",
        "\n",
        "$$\n",
        "\\theta = \\theta^{(0)} - \\eta \\sum_{m=1}^M \\rho^{(m)}\\cdot f^{(m)} (x)\n",
        "$$\n",
        "\n",
        "* Learners are trained to minimize a **proper scoring rule** using a refinment of **gradient boosting**\n",
        "\n",
        "## SBBO - NGBoost\n",
        "\n",
        "* Any base learner can be used\n",
        "\n",
        "* Base learners used: **shallow decision trees** and **lasso linear regressions** \n",
        "\n",
        "* **PPD directly accesible**\n",
        "\n",
        "## Transition\n",
        "\n",
        "General algorithmic things\n",
        "\n",
        "* Initial sample size\n",
        "\n",
        "## Binary Quadratic Problem\n",
        "\n",
        "* We want to maximize\n",
        "\n",
        "\\begin{equation*}\n",
        "x^T Q x - \\lambda \\Vert x \\Vert_1\n",
        "\\end{equation*}\n",
        "\n",
        "over $\\lbrace 0,1 \\rbrace^d$, with $d=10$.\n",
        "\n",
        "* $Q$ is random matrix with indep. Gaussian entries, multiplied element-wise by matrix $K_{ij} = \\exp[-(i-j)^2 / L_c^2]$\n",
        "\n",
        "## Result\n",
        "\n",
        "![](iiia23_files/BQP.png){ width=\"800\" height=\"600\" style=\"display: block; margin: 0 auto\"}\n",
        "\n",
        "::: footer\n",
        "Binary Quadratic Problem \n",
        ":::\n",
        "\n",
        "\n",
        "## Contamination Problem\n",
        "\n",
        "* Food supply with $d$ stages that maybe contaminated\n",
        "\n",
        "* $Z_i$ denotes fraction of food contaminated at $i$-th stage\n",
        "\n",
        "* At stage $i$, prevention effort (with cost $c_i$) can be made $(x_i = 1)$ decreasing contamination a random rate $\\Gamma_i$\n",
        "\n",
        "* If no prevention is taken $(x_i = 0)$, contamination spreads with random rate $\\Lambda_i$\n",
        "\n",
        "\\begin{equation*}\n",
        "Z_i = \\Lambda_i (1-x_i)(1 - Z_{i-1}) + (1 - \\Gamma_i x_i) Z_{i-1}\n",
        "\\end{equation*}\n",
        "\n",
        "![](iiia23_files/clem.jpeg){width=\"400\" height=\"150\" style=\"display: block; margin: 0 auto\"}\n",
        "\n",
        "\n",
        "## Contamination Problem - Goal\n",
        "\n",
        "* Decide for each stage whether to interven or not to minimize cost\n",
        "\n",
        "* Ensuring fraction of cont. food does not exceed $U_i$ with probability at least $1-\\epsilon$\n",
        "\n",
        "* Lagrangian relaxation\n",
        "\n",
        "\\begin{equation*}\n",
        "\\arg\\min_x \\sum_{i=1}^d \\left[ c_i x_i + \\frac{\\rho}{T} \\sum_{k=1}^T 1_{\\lbrace Z_{ik} > U_i \\rbrace} - (1- \\epsilon)\\right] + \\lambda \\Vert x \\Vert_1\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "## Results\n",
        "\n",
        "![](iiia23_files/CON.png){width=\"800\" height=\"600\" style=\"display: block; margin: 0 auto\"}\n",
        "\n",
        "::: footer\n",
        "Contamination Problem \n",
        ":::\n",
        "\n",
        "## Results - Why?\n",
        "\n",
        "![](iiia23_files/CON_acc50.png){width=\"800\" height=\"600\" style=\"display: block; margin: 0 auto\"}\n",
        "\n",
        "::: footer\n",
        "Contamination Problem \n",
        ":::\n",
        "\n",
        "## Results - Why?\n",
        "\n",
        "![](iiia23_files/CON_acc200.png){width=\"800\" height=\"600\" style=\"display: block; margin: 0 auto\"}\n",
        "\n",
        "::: footer\n",
        "Contamination Problem \n",
        ":::\n",
        "\n",
        "## Results - Why?\n",
        "\n",
        "![](iiia23_files/CON_acc400.png){width=\"800\" height=\"600\" style=\"display: block; margin: 0 auto\"}\n",
        "\n",
        "::: footer\n",
        "Contamination Problem \n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Conclusions"
      ],
      "id": "61c5cbbb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}